#!/bin/bash
################################################################################
# Session 13: SPC Hub - Deployment Script
# Semiconductor Lab Platform
#
# Automated deployment for SPC analysis services
#
# Author: Semiconductor Lab Platform Team
# Version: 1.0.0
# Date: October 2025
################################################################################

set -e  # Exit on error
set -u  # Exit on undefined variable

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Deployment environment (default: local)
ENVIRONMENT="${1:-local}"

# Service configuration
SPC_SERVICE_NAME="semiconductorlab-spc"
SPC_SERVICE_PORT=8006
SPC_IMAGE_TAG="semiconductorlab/spc:latest"

################################################################################
# Helper Functions
################################################################################

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[âœ“]${NC} $1"
}

error() {
    echo -e "${RED}[âœ—]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[!]${NC} $1"
}

separator() {
    echo "================================================================================"
}

check_command() {
    if ! command -v "$1" &> /dev/null; then
        error "$1 is not installed. Please install it first."
        exit 1
    fi
}

################################################################################
# Pre-flight Checks
################################################################################

preflight_checks() {
    separator
    log "Running pre-flight checks..."
    separator
    
    # Check required commands
    check_command docker
    check_command docker-compose
    check_command python3
    check_command npm
    
    # Check Python version
    PYTHON_VERSION=$(python3 --version | awk '{print $2}')
    if [[ $(echo "$PYTHON_VERSION 3.9" | awk '{print ($1 >= $2)}') -eq 0 ]]; then
        error "Python 3.9+ required, found $PYTHON_VERSION"
        exit 1
    fi
    success "Python version: $PYTHON_VERSION"
    
    # Check Node version
    NODE_VERSION=$(node --version | sed 's/v//')
    if [[ $(echo "$NODE_VERSION 18.0" | awk '{print ($1 >= $2)}') -eq 0 ]]; then
        error "Node 18+ required, found $NODE_VERSION"
        exit 1
    fi
    success "Node version: $NODE_VERSION"
    
    # Check disk space (need at least 5GB)
    AVAILABLE_SPACE=$(df -BG "$PROJECT_ROOT" | awk 'NR==2 {print $4}' | sed 's/G//')
    if [[ $AVAILABLE_SPACE -lt 5 ]]; then
        warning "Low disk space: ${AVAILABLE_SPACE}GB available (5GB+ recommended)"
    else
        success "Disk space: ${AVAILABLE_SPACE}GB available"
    fi
    
    success "All pre-flight checks passed!"
    echo
}

################################################################################
# Database Setup
################################################################################

setup_database() {
    separator
    log "Setting up database for SPC module..."
    separator
    
    cd "$PROJECT_ROOT/services/database"
    
    # Create SPC tables if they don't exist
    log "Creating SPC tables..."
    
    cat > /tmp/spc_schema.sql << 'EOF'
-- SPC Control Limits Table
CREATE TABLE IF NOT EXISTS spc_control_limits (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    metric VARCHAR(255) NOT NULL,
    subgroup_column VARCHAR(100),
    chart_type VARCHAR(50) NOT NULL,
    ucl NUMERIC NOT NULL,
    lcl NUMERIC NOT NULL,
    centerline NUMERIC NOT NULL,
    sigma NUMERIC,
    sample_size INTEGER,
    computed_from_runs UUID[],
    valid_from TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    valid_until TIMESTAMP WITH TIME ZONE,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_spc_metric ON spc_control_limits(metric);
CREATE INDEX IF NOT EXISTS idx_spc_valid ON spc_control_limits(valid_from, valid_until);

-- SPC Alerts Table
CREATE TABLE IF NOT EXISTS spc_alerts (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    metric VARCHAR(255) NOT NULL,
    severity VARCHAR(20) NOT NULL,
    rule_violated VARCHAR(100) NOT NULL,
    message TEXT NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    data_points JSONB,
    suggested_actions TEXT[],
    acknowledged BOOLEAN DEFAULT FALSE,
    acknowledged_by UUID REFERENCES users(id),
    acknowledged_at TIMESTAMP WITH TIME ZONE,
    resolution TEXT,
    metadata JSONB DEFAULT '{}'
);

CREATE INDEX IF NOT EXISTS idx_spc_alerts_metric ON spc_alerts(metric);
CREATE INDEX IF NOT EXISTS idx_spc_alerts_timestamp ON spc_alerts(timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_spc_alerts_severity ON spc_alerts(severity);

-- SPC Analysis Results Table
CREATE TABLE IF NOT EXISTS spc_analysis_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    metric VARCHAR(255) NOT NULL,
    chart_type VARCHAR(50) NOT NULL,
    analysis_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    data_points_count INTEGER NOT NULL,
    control_limits JSONB NOT NULL,
    capability JSONB,
    statistics JSONB,
    alerts_count INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}'
);

CREATE INDEX IF NOT EXISTS idx_spc_results_metric ON spc_analysis_results(metric);
CREATE INDEX IF NOT EXISTS idx_spc_results_timestamp ON spc_analysis_results(analysis_timestamp DESC);

-- Convert to hypertables for time-series optimization
SELECT create_hypertable('spc_alerts', 'timestamp', if_not_exists => TRUE);
SELECT create_hypertable('spc_analysis_results', 'analysis_timestamp', if_not_exists => TRUE);
EOF
    
    # Run schema creation
    if [[ "$ENVIRONMENT" == "local" ]]; then
        docker-compose exec -T postgres psql -U semiconductorlab -d semiconductorlab < /tmp/spc_schema.sql
    else
        # For staging/production, use proper connection string
        psql $DATABASE_URL < /tmp/spc_schema.sql
    fi
    
    rm /tmp/spc_schema.sql
    
    success "Database schema created successfully!"
    echo
}

################################################################################
# Backend Deployment
################################################################################

deploy_backend() {
    separator
    log "Deploying SPC backend service..."
    separator
    
    cd "$PROJECT_ROOT/services/analysis"
    
    # Create SPC module directory if it doesn't exist
    mkdir -p app/methods/spc
    
    # Copy SPC implementation
    log "Copying SPC implementation files..."
    cp "$SCRIPT_DIR/../outputs/session13_spc_complete_implementation.py" \
       app/methods/spc/spc_analysis.py
    
    # Create __init__.py
    cat > app/methods/spc/__init__.py << 'EOF'
"""
SPC (Statistical Process Control) Analysis Module

Provides control charts, capability analysis, and alert detection.
"""

from .spc_analysis import (
    SPCManager,
    XbarRChart,
    EWMAChart,
    CUSUMChart,
    CapabilityAnalysis,
    ChartType,
    AlertSeverity,
    RuleViolation,
    DataPoint,
    ControlLimits,
    SPCAlert,
    ProcessCapability
)

__all__ = [
    'SPCManager',
    'XbarRChart',
    'EWMAChart',
    'CUSUMChart',
    'CapabilityAnalysis',
    'ChartType',
    'AlertSeverity',
    'RuleViolation',
    'DataPoint',
    'ControlLimits',
    'SPCAlert',
    'ProcessCapability'
]
EOF
    
    # Install Python dependencies
    log "Installing Python dependencies..."
    if [[ -f "requirements.txt" ]]; then
        grep -q "scipy" requirements.txt || echo "scipy>=1.11.0" >> requirements.txt
    else
        cat > requirements_spc.txt << 'EOF'
scipy>=1.11.0
numpy>=1.24.0
pydantic>=2.0.0
EOF
        pip install -r requirements_spc.txt
    fi
    
    # Create FastAPI router for SPC endpoints
    log "Creating SPC API router..."
    mkdir -p app/routers
    
    cat > app/routers/spc.py << 'EOF'
"""
SPC API Router

Endpoints for statistical process control analysis.
"""

from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
from uuid import UUID

from app.methods.spc import SPCManager, ChartType, DataPoint

router = APIRouter(prefix="/api/spc", tags=["spc"])


class DataPointRequest(BaseModel):
    timestamp: str
    value: float
    subgroup: str
    run_id: str
    metadata: Optional[Dict[str, Any]] = None


class AnalysisRequest(BaseModel):
    metric_name: str
    data_points: List[DataPointRequest]
    chart_type: str = "xbar_r"
    lsl: Optional[float] = None
    usl: Optional[float] = None


class AnalysisResponse(BaseModel):
    metric: str
    chart_type: str
    data_count: int
    timestamp: str
    control_limits: Dict[str, Any]
    capability: Optional[Dict[str, Any]]
    statistics: Dict[str, Any]
    alerts: List[Dict[str, Any]]


@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_metric(request: AnalysisRequest):
    """
    Perform SPC analysis on a metric.
    
    Returns control limits, capability indices, and any alerts.
    """
    try:
        # Convert request data to DataPoint objects
        data_points = [
            DataPoint(
                timestamp=datetime.fromisoformat(dp.timestamp.replace('Z', '+00:00')),
                value=dp.value,
                subgroup=dp.subgroup,
                run_id=dp.run_id,
                metadata=dp.metadata
            )
            for dp in request.data_points
        ]
        
        # Run analysis
        manager = SPCManager()
        results = manager.analyze_metric(
            metric_name=request.metric_name,
            data=data_points,
            chart_type=ChartType[request.chart_type.upper()],
            lsl=request.lsl,
            usl=request.usl
        )
        
        return results
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/alerts")
async def get_alerts(
    severity: Optional[str] = None,
    metric: Optional[str] = None,
    limit: int = 50
):
    """Get recent SPC alerts"""
    # TODO: Query from database
    pass


@router.post("/alerts/{alert_id}/acknowledge")
async def acknowledge_alert(alert_id: UUID):
    """Acknowledge an SPC alert"""
    # TODO: Update database
    pass
EOF
    
    success "SPC backend deployed!"
    echo
}

################################################################################
# Frontend Deployment
################################################################################

deploy_frontend() {
    separator
    log "Deploying SPC frontend components..."
    separator
    
    cd "$PROJECT_ROOT/apps/web"
    
    # Create SPC page directory
    mkdir -p src/app/\(dashboard\)/spc
    
    # Copy UI components
    log "Copying SPC UI components..."
    cp "$SCRIPT_DIR/../outputs/session13_spc_ui_components.tsx" \
       src/app/\(dashboard\)/spc/page.tsx
    
    # Install npm dependencies if needed
    log "Checking npm dependencies..."
    if ! npm list recharts &> /dev/null; then
        log "Installing recharts..."
        npm install recharts
    fi
    
    if ! npm list lucide-react &> /dev/null; then
        log "Installing lucide-react..."
        npm install lucide-react
    fi
    
    success "SPC frontend deployed!"
    echo
}

################################################################################
# Testing
################################################################################

run_tests() {
    separator
    log "Running SPC integration tests..."
    separator
    
    cd "$PROJECT_ROOT/services/analysis"
    
    # Copy test file
    mkdir -p tests/integration
    cp "$SCRIPT_DIR/../outputs/test_session13_spc_integration.py" \
       tests/integration/
    
    # Install test dependencies
    pip install pytest pytest-cov pytest-benchmark
    
    # Run tests
    log "Executing test suite..."
    pytest tests/integration/test_session13_spc_integration.py -v --tb=short \
           --cov=app/methods/spc --cov-report=term --cov-report=html
    
    TEST_EXIT_CODE=$?
    
    if [[ $TEST_EXIT_CODE -eq 0 ]]; then
        success "All tests passed!"
    else
        error "Some tests failed! Exit code: $TEST_EXIT_CODE"
        exit $TEST_EXIT_CODE
    fi
    
    echo
}

################################################################################
# Docker Deployment
################################################################################

deploy_docker() {
    separator
    log "Building and deploying Docker containers..."
    separator
    
    cd "$PROJECT_ROOT"
    
    if [[ "$ENVIRONMENT" == "local" ]]; then
        log "Starting services with docker-compose..."
        docker-compose up -d --build
        
        # Wait for services to be healthy
        log "Waiting for services to be healthy..."
        sleep 10
        
        # Check service health
        if docker-compose ps | grep -q "Up"; then
            success "Docker services are running!"
        else
            error "Docker services failed to start!"
            docker-compose logs --tail=50
            exit 1
        fi
    else
        log "Building production Docker image..."
        docker build -t $SPC_IMAGE_TAG \
                     -f services/analysis/Dockerfile \
                     services/analysis/
        
        if [[ "$ENVIRONMENT" == "staging" ]] || [[ "$ENVIRONMENT" == "production" ]]; then
            log "Pushing image to registry..."
            docker push $SPC_IMAGE_TAG
        fi
    fi
    
    echo
}

################################################################################
# Health Check
################################################################################

health_check() {
    separator
    log "Running health checks..."
    separator
    
    # Check database connectivity
    log "Checking database connection..."
    if docker-compose exec -T postgres pg_isready -U semiconductorlab &> /dev/null; then
        success "Database is healthy"
    else
        error "Database connection failed!"
        exit 1
    fi
    
    # Check API endpoints
    log "Checking API health..."
    sleep 5  # Wait for services to stabilize
    
    if curl -sf http://localhost:8000/health > /dev/null; then
        success "API is healthy"
    else
        warning "API health check failed (service may still be starting)"
    fi
    
    # Check frontend
    log "Checking frontend..."
    if curl -sf http://localhost:3000 > /dev/null; then
        success "Frontend is healthy"
    else
        warning "Frontend health check failed (service may still be starting)"
    fi
    
    echo
}

################################################################################
# Generate Documentation
################################################################################

generate_docs() {
    separator
    log "Generating documentation..."
    separator
    
    cd "$PROJECT_ROOT/docs"
    
    # Create SPC documentation
    mkdir -p methods/spc
    
    cat > methods/spc/README.md << 'EOF'
# SPC (Statistical Process Control) Module

## Overview

The SPC module provides comprehensive statistical process control analysis for semiconductor manufacturing, including:

- **Control Charts**: X-bar/R, EWMA, CUSUM
- **Process Capability**: Cp, Cpk, CPU, CPL
- **Rule Detection**: Western Electric and Nelson rules
- **Alert Management**: Real-time detection and triage
- **Dashboard**: Interactive visualization and drill-down

## Features

### Control Charts

#### X-bar and R Charts
- Monitor process mean (X-bar) and variability (R)
- Detect shifts, trends, and special causes
- Subgroup size: 2-10 samples

#### EWMA (Exponentially Weighted Moving Average)
- Sensitive to small process shifts
- Configurable lambda parameter (0.05-0.3)
- Smooths out random variation

#### CUSUM (Cumulative Sum)
- Detects sustained shifts
- Accumulates deviations from target
- Configurable k and h parameters

### Rule Detection

Implements all 8 Western Electric / Nelson rules:
1. One point beyond 3Ïƒ
2. 2 of 3 consecutive points beyond 2Ïƒ
3. 4 of 5 consecutive points beyond 1Ïƒ
4. 8 consecutive points on same side of centerline
5. 6 points in a row trending up or down
6. 14 points alternating up and down
7. 15 points within 1Ïƒ (stratification)
8. 8 points beyond 1Ïƒ (mixture)

### Process Capability

- **Cp**: Potential capability (process spread vs. spec width)
- **Cpk**: Actual capability (accounts for centering)
- **CPU**: Upper capability index
- **CPL**: Lower capability index

Interpretation:
- Cpk â‰¥ 2.0: Excellent (6Ïƒ capable)
- Cpk â‰¥ 1.67: Very Good (5Ïƒ capable)
- Cpk â‰¥ 1.33: Adequate (4Ïƒ capable)
- Cpk â‰¥ 1.0: Marginal (3Ïƒ capable)
- Cpk < 1.0: Poor (process not capable)

## API Usage

### Analyze Metric

```python
from app.methods.spc import SPCManager, ChartType, DataPoint

manager = SPCManager()

# Prepare data
data = [
    DataPoint(
        timestamp=datetime.now(),
        value=100.5,
        subgroup="wafer_1",
        run_id="run_001"
    ),
    # ... more data points
]

# Run analysis
results = manager.analyze_metric(
    metric_name="sheet_resistance",
    data=data,
    chart_type=ChartType.XBAR_R,
    lsl=94.0,  # Lower specification limit
    usl=106.0  # Upper specification limit
)

# Access results
print(f"Cpk: {results['capability']['cpk']:.3f}")
print(f"Alerts: {len(results['alerts'])}")
```

### REST API

```bash
# Analyze metric
curl -X POST http://localhost:8000/api/spc/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "metric_name": "thickness",
    "data_points": [...],
    "chart_type": "xbar_r",
    "lsl": 94.0,
    "usl": 106.0
  }'

# Get alerts
curl http://localhost:8000/api/spc/alerts?severity=critical

# Acknowledge alert
curl -X POST http://localhost:8000/api/spc/alerts/{alert_id}/acknowledge
```

## Performance

- **Analysis speed**: < 1s for 100 samples
- **Large datasets**: < 5s for 1000 samples
- **Real-time updates**: < 2s latency

## Testing

Run the test suite:

```bash
pytest tests/integration/test_session13_spc_integration.py -v --cov
```

## References

- Montgomery, D.C. (2020). *Introduction to Statistical Quality Control*
- Wheeler, D.J. & Chambers, D.S. (1992). *Understanding Statistical Process Control*
- NIST/SEMATECH e-Handbook of Statistical Methods
EOF
    
    success "Documentation generated!"
    echo
}

################################################################################
# Deployment Summary
################################################################################

deployment_summary() {
    separator
    log "Deployment Summary"
    separator
    
    echo
    success "Session 13: SPC Hub deployed successfully!"
    echo
    echo "Components deployed:"
    echo "  âœ“ Database schema (spc_control_limits, spc_alerts, spc_analysis_results)"
    echo "  âœ“ Backend service (FastAPI router + SPC analysis module)"
    echo "  âœ“ Frontend (React/Next.js SPC dashboard)"
    echo "  âœ“ Integration tests (pytest suite with 40+ tests)"
    echo "  âœ“ Documentation (method playbook + API reference)"
    echo
    echo "Access points:"
    echo "  â€¢ Frontend: http://localhost:3000/spc"
    echo "  â€¢ API: http://localhost:8000/api/spc"
    echo "  â€¢ Docs: $PROJECT_ROOT/docs/methods/spc/README.md"
    echo
    echo "Next steps:"
    echo "  1. View SPC dashboard: http://localhost:3000/spc"
    echo "  2. Run integration tests: cd services/analysis && pytest tests/integration/"
    echo "  3. Review documentation: cat docs/methods/spc/README.md"
    echo "  4. Configure alert notifications (email, Slack, etc.)"
    echo "  5. Import historical data for baseline control limits"
    echo
    separator
}

################################################################################
# Main Deployment Flow
################################################################################

main() {
    clear
    echo "================================================================================"
    echo "  Session 13: SPC Hub - Automated Deployment"
    echo "  Semiconductor Lab Platform"
    echo "================================================================================"
    echo
    log "Starting deployment for environment: $ENVIRONMENT"
    echo
    
    # Run deployment steps
    preflight_checks
    setup_database
    deploy_backend
    deploy_frontend
    
    if [[ "$ENVIRONMENT" != "production" ]]; then
        run_tests
    fi
    
    deploy_docker
    health_check
    generate_docs
    deployment_summary
    
    success "Deployment complete! ðŸŽ‰"
}

# Execute main function
main "$@"
